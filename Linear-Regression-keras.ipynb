{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.datasets import boston_housing\n",
    "import math\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense , Dropout , Activation , Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam , SGD , RMSprop\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Admission_Predict_Ver1.1.csv')\n",
    "df.head()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('2.txt',delimiter=',')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:,0:4]\n",
    "y = data[:,4]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_california_housing()\n",
    "X_prime = data.data\n",
    "y_prime = data.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_prime_train,X_prime_test,y_prime_train,y_prime_test = train_test_split(X_prime,y_prime,train_size=0.8,random_state=2,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "#X_prime_train_scaled = scaler.fit_transform(X_prime_train)\n",
    "#X_prime_test_scaled  = scaler.transform(X_prime_test)\n",
    "#X_prime_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.8)\n",
    "X_train.shape\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize train and test data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.keras.initializers.HeNormal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first basic model\n",
    "def basic_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32,input_dim=X_train_scaled.shape[1],activation=\"relu\"))\n",
    "    model.add(Dense(1,activation='relu'))\n",
    "    model.compile(optimizer=Adam(0.001),loss=\"mean_squared_error\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a  model which has one hidden layer and more input neurons\n",
    "def advanced_model_1():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64,input_dim=X_train_scaled.shape[1],activation='relu'))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dense(1,activation='relu'))\n",
    "    model.compile(optimizer=Adam(0.001),loss=\"mean_squared_error\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a model which has one hidden layer and more input neurons\n",
    "def advanced_model_2():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128,input_dim=X_train_scaled.shape[1],activation='relu'))\n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dense(1,activation='relu'))\n",
    "    model.compile(optimizer=Adam(0.001),loss=\"mean_squared_error\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a model with He normal initializer\n",
    "def advanced_model_3():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128,input_dim=X_train_scaled.shape[1],activation='relu',kernel_initializer=initializer))\n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dense(1,activation='relu'))\n",
    "    model.compile(optimizer=Adam(0.001),loss=\"mean_squared_error\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a model with sigmoid activation\n",
    "def advanced_model_4():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32,activation='sigmoid'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=Adam(0.001),loss=\"mean_squared_error\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a model with relu activation and erasing output layer activation with SGD optimizer\n",
    "def advanced_model_5():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=SGD(0.001),loss=\"mean_squared_error\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a model with more layers and relu activation and mean squared logarithmic error\n",
    "def advanced_model_6():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=Adam(0.001),loss=\"mean_squared_logarithmic_error\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a model with less layers than the previous model and relu activation and mean squared logarithmic error\n",
    "def advanced_model_7():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=Adam(0.001),loss=\"mean_squared_logarithmic_error\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same with previous model but with tanh activation function\n",
    "def advanced_model_8():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128,activation='tanh'))\n",
    "    model.add(Dense(64,activation='tanh'))\n",
    "    model.add(Dense(32,activation='tanh'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=Adam(0.001),loss=\"mean_squared_logarithmic_error\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add dropout for every layer except last layer\n",
    "def advanced_model_9():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=Adam(0.001),loss=\"mean_squared_logarithmic_error\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model with dropout with bigger learning rate for Adam\n",
    "def advanced_model_10():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=Adam(0.002),loss=\"mean_squared_logarithmic_error\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_model_11():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=RMSprop(0.002),loss=\"mean_squared_logarithmic_error\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_model_12():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation='relu'))\n",
    "    model.compile(optimizer=Adam(0.002),loss=\"mean_squared_logarithmic_error\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=basic_model()\n",
    "fit1=model.fit(X_train_scaled,y_train,batch_size=1024,epochs=100,validation_split=0.01)\n",
    "print(\"predication Loss\")\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "model.evaluate(X_test_scaled,y_test)\n",
    "plt.plot(fit1.history['loss'])\n",
    "plt.plot(fit1.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = advanced_model_1()\n",
    "fit2=model.fit(X_train_scaled,y_train,batch_size=1024,epochs=100,validation_split=0.01)\n",
    "print(\"predication Loss\")\n",
    "y_pred = model.predict(X_test_scaled) \n",
    "model.evaluate(X_test_scaled,y_test)\n",
    "plt.plot(fit2.history['loss'])\n",
    "plt.plot(fit2.history['val_loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = advanced_model_2()\n",
    "fit3 = model.fit(X_train_scaled,y_train,batch_size=1024,epochs=100,validation_split=0.01)\n",
    "print(\"predication Loss\")\n",
    "y_pred = model.predict(X_train_scaled)\n",
    "model.evaluate(X_test_scaled,y_test)\n",
    "plt.plot(fit3.history['loss'])\n",
    "plt.plot(fit3.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = advanced_model_3()\n",
    "fit4 =model.fit(X_train_scaled,y_train,batch_size=1024,epochs=100,validation_split=0.01)\n",
    "print(\"predication Loss\")\n",
    "y_pred = model.predict(X_train_scaled)\n",
    "model.evaluate(X_test_scaled,y_test)\n",
    "plt.plot(fit4.history['loss'])\n",
    "plt.plot(fit4.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = advanced_model_4()\n",
    "fit5 = model.fit(X_train_scaled,y_train,batch_size=1024,epochs=100,validation_split=0.01)\n",
    "print(\"Prediction Loss\")\n",
    "y_pred = model.predict(X_train_scaled)\n",
    "model.evaluate(X_test_scaled,y_test)\n",
    "plt.plot(fit5.history['loss'])\n",
    "plt.plot(fit5.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = advanced_model_5()\n",
    "fit6 = model.fit(X_train_scaled,y_train,batch_size=1024,epochs=100,validation_split=0.01)\n",
    "print(\"predication Loss\")\n",
    "y_pred = model.predict(X_train_scaled)\n",
    "model.evaluate(X_test_scaled,y_test)\n",
    "plt.plot(fit6.history['loss'])\n",
    "plt.plot(fit6.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = advanced_model_6()\n",
    "fit7 = model.fit(X_train_scaled,y_train,batch_size=1024,epochs=100,validation_split=0.01)\n",
    "print(\"predication Loss\")\n",
    "y_pred = model.predict(X_train_scaled)\n",
    "model.evaluate(X_test_scaled,y_test)\n",
    "plt.plot(fit7.history['loss'])\n",
    "plt.plot(fit7.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = advanced_model_7()\n",
    "fit8 = model.fit(X_train_scaled,y_train,batch_size=1024,epochs=100,validation_split=0.01)\n",
    "print(\"predication Loss\")\n",
    "y_pred = model.predict(X_train_scaled)\n",
    "model.evaluate(X_test_scaled,y_test)\n",
    "plt.plot(fit8.history['loss'])\n",
    "plt.plot(fit8.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = advanced_model_8()\n",
    "fit9 = model.fit(X_train_scaled,y_train,batch_size=1024,epochs=100,validation_split=0.01)\n",
    "print(\"predication Loss\")\n",
    "y_pred = model.predict(X_train_scaled)\n",
    "model.evaluate(X_test_scaled,y_test)\n",
    "plt.plot(fit9.history['loss'])\n",
    "plt.plot(fit9.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = advanced_model_9()\n",
    "fit10 = model.fit(X_train_scaled,y_train,batch_size=1024,epochs=100,validation_split=0.01)\n",
    "print(\"predication Loss\")\n",
    "y_pred = model.predict(X_train_scaled)\n",
    "model.evaluate(X_test_scaled,y_test)\n",
    "plt.plot(fit10.history['loss'])\n",
    "plt.plot(fit10.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = advanced_model_10()\n",
    "fit11 = model.fit(X_train_scaled,y_train,batch_size=1024,epochs=100,validation_split=0.01)\n",
    "print(\"predication Loss\")\n",
    "y_pred = model.predict(X_train_scaled)\n",
    "model.evaluate(X_test_scaled,y_test)\n",
    "plt.plot(fit11.history['loss'])\n",
    "plt.plot(fit11.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = advanced_model_11()\n",
    "fit12 = model.fit(X_train_scaled,y_train,batch_size=1024,epochs=100,validation_split=0.01)\n",
    "print(\"predication Loss\")\n",
    "y_pred = model.predict(X_train_scaled)\n",
    "model.evaluate(X_test_scaled,y_test)\n",
    "plt.plot(fit12.history['loss'])\n",
    "plt.plot(fit12.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = advanced_model_12()\n",
    "fit13 = model.fit(X_train_scaled,y_train,batch_size=1024,epochs=100,validation_split=0.01)\n",
    "print(\"predication Loss\")\n",
    "y_pred = model.predict(X_train_scaled)\n",
    "model.evaluate(X_test_scaled,y_test)\n",
    "plt.plot(fit13.history['loss'])\n",
    "plt.plot(fit13.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = advanced_model_12()\n",
    "fit14 = model.fit(X_train_scaled,y_train,batch_size=2048,epochs=100,validation_split=0.01)\n",
    "print(\"predication Loss\")\n",
    "y_pred = model.predict(X_train_scaled)\n",
    "model.evaluate(X_test_scaled,y_test)\n",
    "plt.plot(fit14.history['loss'])\n",
    "plt.plot(fit14.history['val_loss'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
